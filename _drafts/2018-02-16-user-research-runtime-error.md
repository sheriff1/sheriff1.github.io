---
layout: post

title: "User research runtime error"

subtitle: "Basically you can't truly evaluate something until someone uses it"

date: 2018-03-03

published: true
---

- User Research Runtime Error: Basically you can't truly evaluate something until someone uses it
	- the "better" result of this is that users complain directly to you via feedback or customer support
	- the worse result of this runtime error is when they do not tell you that it was irritating/not useful for them.
		- This result sucks because you may not hear about it at all and assume all is right with the world.
		- As a member of your team, you may already inherently feel that this runtime error is going to occur; but without data it can be harder to make a case. "Hey guys, without us informing the user about how to rectify this issue that may come up, they may think things are hunky-dory...maybe we should do something about it?" -- "We'll hear it in feedback. If there's any support cases that come up, we'll be sure to circle back" -- (muttered under breath): "Well we won't get any cases until next month when this runtime error will be long forgottennnnnn..."

- I do not champion the idea of using this as rationale to avoid usability testing, interviewing, surveying, data analysis, or any other way to gather insight that will lead to logical progressions of a product.

- This idea extends to product development as a whole already, but is slightly easier to overcome. You can assume a person will become a customer of your product based on an MVP you have put together, and if your MVP is end-to-end (like it should be), then you have enough to avoid the runtime error of "is my product is going to get off the ground".

- What should be done?
	- Allow your intuition to lead you to build what is right.
